{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'control_net'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Unet3D\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDiffusion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Diffusion_Control\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mEMA\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExponentialMovingAverage\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSimpleShapeDataset\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mVoxelData\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VoxelDataset, ConditionDataset\n",
      "File \u001b[0;32m~/Desktop/diffusion_project/3d_generation/model/Diffusion.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Unet3D\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcontrol_net\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnetWithControlNet\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDiffusion_Control\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, image_size, in_channels, time_embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, base_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, dim_mults\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m8\u001b[39m]):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'control_net'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from model.unet import Unet3D\n",
    "from model.Diffusion import Diffusion_Control\n",
    "from model.EMA import ExponentialMovingAverage\n",
    "\n",
    "from dataset.SimpleShapeDataset.VoxelData import VoxelDataset, ConditionDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from utils.visualization import visualize_voxel_map\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_dataset_dir = \"dataset/SimpleShapeDataset/voxel_datasets\"\n",
    "\n",
    "voxel_dataset = VoxelDataset(voxel_dataset_dir)\n",
    "\n",
    "# Create the DataLoader\n",
    "batch_size = 2\n",
    "voxel_dataloader = DataLoader(voxel_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "voxel_dataset_dir = \"dataset/SimpleShapeDataset/condition_datasets\"\n",
    "\n",
    "voxel_dataset = ConditionDataset(voxel_dataset_dir)\n",
    "\n",
    "# Create the DataLoader\n",
    "batch_size = 2\n",
    "condition_dataloader = DataLoader(voxel_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss, self).__init__()\n",
    "        self.mse = nn.MSELoss(reduction='mean')\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        return torch.sqrt(self.mse(output, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "batch_size = 2\n",
    "model_ema_steps = 10\n",
    "num_epochs = 70\n",
    "model_ema_decay = 0.995\n",
    "\n",
    "# Define the model\n",
    "model = Diffusion(\n",
    "    timesteps=1000,\n",
    "    image_size=64,\n",
    "    in_channels=1,\n",
    "    base_dim=32,\n",
    "    dim_mults=[1, 2, 4, 8]\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=100,\n",
    "    num_training_steps=(len(voxel_dataloader) * num_epochs),\n",
    ")\n",
    "adjust = 1 * batch_size * model_ema_steps / num_epochs\n",
    "alpha = 1.0 - model_ema_decay\n",
    "alpha = min(1.0, alpha * adjust)\n",
    "model_ema = ExponentialMovingAverage(model, device=device, decay=1.0 - alpha)\n",
    "\n",
    "loss_fn = RMSELoss()\n",
    "min_loss = np.inf\n",
    "global_steps = 1074000\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "checkpoint_path = \"results/steps_01074000.pt\"\n",
    "\n",
    "# Load checkpoint if exists\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(\"Loading best checkpoint...\")\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    model_ema.load_state_dict(checkpoint[\"model_ema\"])\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for (voxel_batch, condition_batch) in zip(voxel_dataloader, condition_dataloader):\n",
    "        # Prepare inputs\n",
    "        noise = torch.randn_like(voxel_batch).to(device)\n",
    "        voxel_batch = voxel_batch.to(device)\n",
    "        condition_batch = condition_batch.to(device)\n",
    "\n",
    "        # Model forward pass\n",
    "        pred = model(voxel_batch, noise, condition=condition_batch)  # Ensure model supports conditioning\n",
    "        noise = noise.unsqueeze(1)\n",
    "        loss = loss_fn(pred, noise)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Update EMA\n",
    "        if global_steps % model_ema_steps == 0:\n",
    "            model_ema.update_parameters(model)\n",
    "\n",
    "        # Logging\n",
    "        if global_steps % 100 == 0:\n",
    "            print(f\"Epoch[{epoch + 1}/{num_epochs}], Step[{global_steps}], Loss: {loss.item():.4f}, lr: {lr_scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if loss.item() < min_loss and epoch > 1:\n",
    "            min_loss = loss.item()\n",
    "            torch.save(\n",
    "                {\"model\": model.state_dict(), \"model_ema\": model_ema.state_dict()},\n",
    "                f\"results/best.pt\"\n",
    "            )\n",
    "        global_steps += 1\n",
    "\n",
    "    # Save checkpoint\n",
    "    torch.save(\n",
    "        {\"model\": model.state_dict(), \"model_ema\": model_ema.state_dict()},\n",
    "        f\"results/steps_{global_steps:08d}.pt\"\n",
    "    )\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "print(device)\n",
    "batch_size = 2; model_ema_steps = 10;num_epochs = 20; model_ema_decay = 0.995\n",
    "\n",
    "# Define the model\n",
    "model = Diffusion(timesteps=1000,\n",
    "                        image_size=64,\n",
    "                        in_channels=1,\n",
    "                        base_dim=32,\n",
    "                        dim_mults=[1,2, 4,8]).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "optimizer=optimizer,\n",
    "num_warmup_steps=100,\n",
    "num_training_steps=(len(voxel_dataloader) * num_epochs),\n",
    ")\n",
    "adjust = 1* batch_size * model_ema_steps / num_epochs\n",
    "alpha = 1.0 - model_ema_decay\n",
    "alpha = min(1.0, alpha * adjust)\n",
    "model_ema = ExponentialMovingAverage(model, device=device, decay=1.0 - alpha)\n",
    "# Example usage:\n",
    "# loss_fn = RMSELoss()\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "min_loss = np.inf\n",
    "global_steps = 40000\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "checkpoint_path = \"results/steps_01174000.pt\"\n",
    "\n",
    "# if os.path.exists(checkpoint_path):\n",
    "#     print(\"Loading best checkpoint...\")\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "save_dir = \"output_voxel_maps\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "model_ema.load_state_dict(checkpoint[\"model_ema\"])\n",
    "# model_ema = ExponentialMovingAverage(model, device=device, decay=1.0 - 0.1)\n",
    "samples = []\n",
    "for i in range(32):\n",
    "        samples.append(model_ema.module.sampling(1, device=device))\n",
    "\n",
    "for i in range(32):\n",
    "        voxel_1d_array = samples[i].cpu().numpy()\n",
    "        # voxel_1d_array += 1\n",
    "        # voxel_1d_array *=0.5\n",
    "        binary_data = (voxel_1d_array > 0.5).astype(int)\n",
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "        from mpl_toolkits.mplot3d import Axes3D\n",
    "        # print(binary_data)\n",
    "        # Parameters for voxel map\n",
    "        voxel_size = 0.25\n",
    "        grid_size = 64\n",
    "\n",
    "        # Reshape binary data into 8x8x8 by averaging blocks of 4x4x4\n",
    "        reshaped_data = binary_data.reshape(grid_size, 1,grid_size, 1, grid_size, 1).mean(axis=(1, 3, 5))\n",
    "        voxel_data = (reshaped_data > 0.5).astype(int)  # Convert to binary based on average\n",
    "\n",
    "        # Prepare the 3D plot\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "        # Create a 3D grid for the voxel map (dimensions + 1 to align with voxel corners)\n",
    "        x, y, z = np.indices((grid_size + 1, grid_size + 1, grid_size + 1)) * voxel_size\n",
    "\n",
    "        # Display voxels\n",
    "        filled_voxels = (voxel_data == 1)\n",
    "\n",
    "        ax.voxels(x, y, z, filled_voxels, \n",
    "                facecolors=\"blue\", edgecolors=\"black\", alpha=0.7)\n",
    "\n",
    "        # Set labels and aspect ratio\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        ax.set_aspect('auto')\n",
    "        plt.title(\"8x8x8 Voxel Map\")\n",
    "\n",
    "        # Show plot\n",
    "        # plt.show()\n",
    "        save_path = os.path.join(save_dir, f\"sample_{i+33}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        plt.close(fig)\n",
    "\n",
    "    # plt.savefig(save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
